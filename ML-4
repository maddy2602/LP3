# ----------------------------------
# Practical 4: Diabetes Prediction using KNN
# ----------------------------------

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score, classification_report,
    roc_auc_score, roc_curve
)

# -----------------------------
# Load dataset
# -----------------------------
data = pd.read_csv("diabetes.csv")
print("Dataset Preview:\n", data.head())

# Check missing values
print("\nMissing values before replacement:\n", data.isnull().sum())

# -----------------------------
# Replace 0 values with NaN (Invalid = Treated as Missing)
# -----------------------------
cols_to_replace = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for col in cols_to_replace:
    data[col] = data[col].replace(0, np.nan)

print("\nMissing values after replacement:\n", data.isnull().sum())

# -----------------------------
# Fill NaN with Median or Mean
# -----------------------------
data['Glucose'].fillna(data['Glucose'].mean(), inplace=True)
data['BloodPressure'].fillna(data['BloodPressure'].mean(), inplace=True)
data['SkinThickness'].fillna(data['SkinThickness'].median(), inplace=True)
data['Insulin'].fillna(data['Insulin'].median(), inplace=True)
data['BMI'].fillna(data['BMI'].median(), inplace=True)

print("\nMissing values after imputation:\n", data.isnull().sum())

# -----------------------------
# Visualization – Class Distribution
# -----------------------------
plt.figure(figsize=(8, 5))
sns.countplot(x='Outcome', data=data)
plt.title("Class Distribution (0 = No Diabetes, 1 = Diabetes)")
plt.show()

# -----------------------------
# Feature Scaling
# -----------------------------
scaler = StandardScaler()
X = pd.DataFrame(scaler.fit_transform(data.drop("Outcome", axis=1)), columns=data.columns[:-1])
y = data["Outcome"]

# -----------------------------
# Train-Test Split
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# -----------------------------
# KNN Model - Find Best K
# -----------------------------
train_scores, test_scores = [], []
for k in range(1, 15):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    train_scores.append(knn.score(X_train, y_train))
    test_scores.append(knn.score(X_test, y_test))

best_k = np.argmax(test_scores) + 1
print(f"\n✅ Best K = {best_k}, Test Accuracy = {max(test_scores) * 100:.2f}%")

# Train final model
knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# -----------------------------
# Evaluation Metrics
# -----------------------------
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1 Score: {f1:.4f}")

# -----------------------------
# Confusion Matrix Heatmap
# -----------------------------
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap="YlGnBu", fmt="d")
plt.title("Confusion Matrix Heatmap")
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.show()

# -----------------------------
# ROC Curve
# -----------------------------
y_pred_proba = knn.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)

plt.figure(figsize=(7, 5))
plt.plot(fpr, tpr, label=f"KNN (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.show()

# -----------------------------
# Hyperparameter Tuning – GridSearchCV
# -----------------------------
param_grid = {"n_neighbors": np.arange(1, 30)}
knn_cv = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
knn_cv.fit(X, y)

print("\nBest Parameters Found:", knn_cv.best_params_)
print("Best Cross-Validation Score:", knn_cv.best_score_)
